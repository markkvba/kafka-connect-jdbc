# Kafka Connect JDBC - Deployment & Development Guide

This document describes the custom modifications and deployment automation added to this fork of kafka-connect-jdbc.

## Custom Modifications

### PostgreSQL Null UTF-8 Character Handling

**File**: `src/main/java/io/confluent/connect/jdbc/dialect/PostgreSqlDatabaseDialect.java`

PostgreSQL does not allow null UTF-8 characters (`\u0000`) in string values, which can occur when migrating legacy data from systems like Oracle that permit them. This fork includes a fix that automatically strips null characters before binding string values to prepared statements.

**Change**: Lines 521-529 in `maybeBindPrimitive()` method
```java
case STRING: {
  // PostgreSQL does not allow null UTF-8 characters (\u0000) in string values
  // Strip them to handle legacy data from systems like Oracle that permit them
  String newValue = ((String) value).replace("\u0000", "");
  if (!newValue.equals(value)) {
    log.warn("Removed null UTF-8 character(s) from value in column '{}'", fieldName);
  }
  statement.setString(index, newValue);
  return true;
}
```

**Test Coverage**: `src/test/java/io/confluent/connect/jdbc/dialect/PostgreSqlDatabaseDialectTest.java`

The `bindFieldStringValueWithNulls()` test validates that input strings with multiple null characters are correctly cleaned during binding.

## Build Configuration

### System Requirements
- **Java**: 11 (JDK 11 or later, currently tested and verified with Java 11)
- **Maven**: 3.6+ (for building)

### Maven Assembly

The build creates a complete plugin distribution package:
```
target/kafka-connect-jdbc-<version>-package/
├── share/java/kafka-connect-jdbc/           (all JARs and dependencies)
├── share/doc/kafka-connect-jdbc/            (README, LICENSE, NOTICE, docs)
├── etc/kafka-connect-jdbc/                  (example configuration files)
└── manifest.json                            (auto-generated by kafka-connect-maven-plugin)
```

Build with:
```bash
mvn clean package -DskipTests
```

## Jenkins CI/CD Pipeline

**File**: `Jenkinsfile` (at repository root)

### Configuration Requirements

Before setting up the Jenkins pipeline, configure the following:

#### Environment Variables (per environment)
Configure as Jenkins Global properties:

**Development (dev)**:
- `KAFKA_CONNECT_HOSTS_DEV`: Space-separated list of dev host IPs/names

**SQA (sqa)**:
- `KAFKA_CONNECT_HOSTS_SQA`: Space-separated list of SQA hosts

**Stage (stage)**:
- `KAFKA_CONNECT_HOSTS_STAGE`: Space-separated list of stage hosts (typically 2 nodes)

**Production (prod)**:
- `KAFKA_CONNECT_HOSTS_PROD`: Space-separated list of prod hosts (typically 2 nodes)

Example configuration:
```
KAFKA_CONNECT_HOSTS_STAGE=10.0.1.10 10.0.1.11
```

### Jenkins Setup Instructions

#### Step 1: Verify SSH Key on Jenkins File System

The Jenkinsfile uses the SSH key at `~/.ssh/kafka_connect_key` (shared with SMT pipeline).

1. Verify the SSH key exists on your Jenkins server:
   ```bash
   ssh to jenkins-server
   ls -la ~/.ssh/kafka_connect_key
   ```

2. The key should already be in place. If not, generate it as root with ssh-keygen:
   ```bash
   sudo ssh-keygen -t rsa -f ~/.ssh/kafka_connect_key -N ""
   ```

3. Test SSH access from Jenkins:
   ```bash
   sudo -u jenkins ssh -i ~/.ssh/kafka_connect_key ec2-user@<target-host> "echo 'SSH working'"
   ```

#### Step 2: Configure Global Tools

1. Go to **Manage Jenkins** > **Global Tool Configuration**
2. Locate **JDK**:
   - Ensure a JDK installation named `JDK11` exists
   - If not, click **Add JDK** and configure:
     - **Name**: `JDK11`
     - **Install automatically**: checked
     - **Add installer**: Select "Install from java.sun.com" or use automatic detection
3. Locate **Maven**:
   - Ensure a Maven installation named `Maven3` exists
   - If not, click **Add Maven** and configure:
     - **Name**: `Maven3`
     - **Install automatically**: checked
4. Click **Save**

#### Step 3: Configure Environment Variables

The Jenkinsfile reads `KAFKA_CONNECT_HOSTS_*` environment variables for each environment (dev, sqa, stage, prod).

**Recommended: Jenkins Global Configuration**

1. Go to **Manage Jenkins** > **Configure System** > **Global properties**
2. Check **Environment variables**
3. Add variables for each environment:

**Development (dev)**:
```
KAFKA_CONNECT_HOSTS_DEV=<dev-host-ip>
```

**SQA (sqa)**:
```
KAFKA_CONNECT_HOSTS_SQA=<sqa-host-ip>
```

**Stage (stage)** - space-separated host list:
```
KAFKA_CONNECT_HOSTS_STAGE=<stage-host-1> <stage-host-2>
```

**Production (prod)** - space-separated host list:
```
KAFKA_CONNECT_HOSTS_PROD=<prod-host-1> <prod-host-2>
```

Example values:
```
KAFKA_CONNECT_HOSTS_DEV=10.0.1.5
KAFKA_CONNECT_HOSTS_SQA=10.0.1.6
KAFKA_CONNECT_HOSTS_STAGE=10.0.2.10 10.0.2.11
KAFKA_CONNECT_HOSTS_PROD=10.0.3.10 10.0.3.11
```

4. Click **Save**

#### Step 4: Create Multi-Branch Pipeline Job

1. In Jenkins, click **New Item**
2. Enter job name: `RES kafka-connect-jdbc`
3. Select **Multibranch Pipeline**
4. Click **OK**
5. Configure:
   - **Description**: Kafka Connect JDBC CI/CD Pipeline
   - Under **Branch Sources** section:
     - Click **Add source** > **Git**
     - **Project Repository**: `https://github.com/YOUR_USERNAME/kafka-connect-jdbc.git` (or your fork URL)
     - **Credentials**: Select appropriate Git credentials if needed
   - Under **Scan Multibranch Pipeline Triggers**:
     - Check **Periodically if not otherwise run** with interval (e.g., 1 hour)
   - Click **Save**

The pipeline will automatically detect the `Jenkinsfile` in each branch and PR.

#### Step 5: Test the Pipeline

1. Click **Build with Parameters**
2. Select `ENVIRONMENT`: `dev`
3. Leave `DEPLOY_TO_KAFKA_CONNECT`: unchecked (to test build only)
4. Click **Build**
5. Monitor build output in **Console Output**
6. Verify build succeeds and package distribution is created

#### Step 6: Enable Deployment

Once build is verified:
1. Click **Build with Parameters**
2. Select `ENVIRONMENT`: `dev`
3. Check `DEPLOY_TO_KAFKA_CONNECT`: checked
4. Click **Build**
5. Monitor deployment progress and service status in console output

### Pipeline Stages

1. **Checkout**: Clone repository
2. **Build**: `mvn clean package -DskipTests` - Creates package distribution
3. **Archive**: Verify package distribution and archive artifacts
4. **Deploy to Kafka Connect**: (conditional on `DEPLOY_TO_KAFKA_CONNECT` parameter)
   - Tars the package distribution
   - SCPs to each target host
   - Extracts and runs deployment script
   - Monitors service startup with intelligent polling

### Running the Pipeline

1. In Jenkins, select the kafka-connect-jdbc job
2. Click "Build with Parameters"
3. Select target `ENVIRONMENT` (dev, sqa, stage, prod)
4. Check `DEPLOY_TO_KAFKA_CONNECT` to enable deployment
5. Click "Build"

## Deployment Script

**File**: `scripts/deploy.sh`

### Usage
```bash
bash deploy.sh <package_directory>
```

### Parameters
- `<package_directory>`: Path to the package distribution directory (e.g., `/tmp/kafka-connect-jdbc-10.10.0-SNAPSHOT-package`)

### Behavior

1. **Validation**: Verifies package directory exists and contains `manifest.json`
2. **Cleanup**: Removes existing plugin directory at `/usr/share/java/connect_plugins/confluentinc-kafka-connect-jdbc/`
3. **Deployment**: Copies entire package structure (JARs, docs, config, manifest)
4. **Permissions**: Sets ownership to `cp-kafka-connect:confluent` with 755 dirs, 644 files
5. **Service Control**:
   - Stops Kafka Connect service
   - Waits for all KConnector services to show as stopped
   - Starts Kafka Connect
   - Waits for KConnector services to be ready
6. **Verification**: Displays final status of all services

### Execution

Deploys the package and restarts only Kafka Connect services (up to 10 seconds, 5 polling attempts):
```bash
bash deploy.sh /tmp/package
```

### Service Status Monitoring

The script uses intelligent polling (max 5-30 attempts, 2-second intervals) to wait for services to transition state, rather than fixed timeouts. It checks output from `kafka_status.sh` for the `✔` checkmark indicating running services.

## Development Workflow

### Building Locally
```bash
# Build package distribution
mvn clean package -DskipTests

# Build and run tests
mvn clean package

# Build with specific profiles
mvn clean package -Pstandalone -DskipTests
```

### Testing the PostgreSQL Fix
```bash
# Run specific test
mvn test -Dtest=PostgreSqlDatabaseDialectTest#bindFieldStringValueWithNulls

# Run all JDBC dialect tests
mvn test -Dtest=PostgreSqlDatabaseDialectTest
```

### Local Verification
```bash
# Verify package structure
ls -la target/kafka-connect-jdbc-*-package/
ls -la target/kafka-connect-jdbc-*-package/share/java/kafka-connect-jdbc/
cat target/kafka-connect-jdbc-*-package/manifest.json
```

## Deployment to Production Checklist

- [ ] Verify PostgreSQL null UTF-8 fix is appropriate for your data
- [ ] Test locally with `mvn clean package -DskipTests`
- [ ] Configure Jenkins credentials (SSH key)
- [ ] Configure Jenkins environment variables for all target environments
- [ ] Test pipeline in dev environment first
- [ ] Review service status output before moving to stage/prod
- [ ] Ensure backup of existing plugin directory on target hosts
- [ ] Monitor Kafka Connect logs after deployment

## Troubleshooting

### Deploy Script Fails: "manifest.json not found"
- Verify Maven build completed successfully with `-Ppackage` assembly
- Check that `target/kafka-connect-jdbc-*-package/` directory exists locally

### Service Status Polling Times Out
- Check that `kafka_status.sh` is available on remote hosts at `/usr/local/bin/res_scripts/kafka_status.sh`
- Verify service names match exactly in Jenkins configuration
- Review Kafka Connect logs on target host: `/var/log/kafka/`

### SCP/SSH Connection Failed
- Verify SSH key credentials are configured in Jenkins
- Test SSH access manually: `ssh -i <key> ec2-user@<host>`
- Check firewall rules allow SSH from Jenkins host

### Permission Denied on Plugin Directory
- Verify user running deployment script has `sudo` privileges
- Check that target host allows `sudo` without password for script operations

## References

- [Confluent Kafka Connect JDBC Documentation](https://docs.confluent.io/kafka-connect-jdbc/current/)
- [Maven Assembly Plugin](https://maven.apache.org/plugins/maven-assembly-plugin/)
- [Kafka Connect Plugin Development](https://docs.confluent.io/kafka-connect/current/development.html)
